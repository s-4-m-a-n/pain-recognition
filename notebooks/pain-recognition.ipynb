{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-08T10:37:24.404432Z","iopub.execute_input":"2022-12-08T10:37:24.404953Z","iopub.status.idle":"2022-12-08T10:37:24.439524Z","shell.execute_reply.started":"2022-12-08T10:37:24.404826Z","shell.execute_reply":"2022-12-08T10:37:24.438578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:37:29.431587Z","iopub.execute_input":"2022-12-08T10:37:29.432029Z","iopub.status.idle":"2022-12-08T10:37:29.437473Z","shell.execute_reply.started":"2022-12-08T10:37:29.431991Z","shell.execute_reply":"2022-12-08T10:37:29.435743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_label_img(IMAGE_DATASET_PATH, LABEL_DATASET_PATH, index1, index2, index3):\n    ''' return image with corresponding label'''\n    # retrieving level 2\n    n = sorted(os.listdir(LABEL_DATASET_PATH))[index1]\n    level_1 = os.path.join(LABEL_DATASET_PATH, n)\n    m = sorted(os.listdir(level_1))[index2]\n    level_2 = os.path.join(level_1, m)\n    o = sorted(os.listdir(level_2))[index3] \n    level_3 = os.path.join(level_2, o)\n    \n    with open(level_3) as f:\n        label = f.readline().strip()\n    \n    # retrieving level 3\n    n_i = sorted(os.listdir(IMAGE_DATASET_PATH))[index1]\n    level_1_i = os.path.join(IMAGE_DATASET_PATH, n_i)\n    m_i = sorted(os.listdir(level_1_i))[index2]\n    level_2_i = os.path.join(level_1_i, m_i)\n    o_i = sorted(os.listdir(level_2_i))[index3] \n    level_3_i = os.path.join(level_2_i, o_i)\n    \n    #reading image\n    img = plt.imread(level_3_i)\n    return img, label\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:14:41.461503Z","iopub.execute_input":"2022-12-08T05:14:41.461938Z","iopub.status.idle":"2022-12-08T05:14:41.472522Z","shell.execute_reply.started":"2022-12-08T05:14:41.461907Z","shell.execute_reply":"2022-12-08T05:14:41.471133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LABEL_DATASET_PATH = \"/kaggle/input/emotionpain/Frame_Labels/Frame_Labels/PSPI\"\nIMAGE_DATASET_PATH = \"/kaggle/input/emotionpain/Images/Images\"\nimage, label = get_label_img(IMAGE_DATASET_PATH, LABEL_DATASET_PATH , 0, 0, 0)\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:37:38.795725Z","iopub.execute_input":"2022-12-08T10:37:38.796223Z","iopub.status.idle":"2022-12-08T10:37:38.885326Z","shell.execute_reply.started":"2022-12-08T10:37:38.796177Z","shell.execute_reply":"2022-12-08T10:37:38.883074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### display image","metadata":{}},{"cell_type":"code","source":"def show_img_label(index1, index2, index3):\n    LABEL_DATASET_PATH = \"/kaggle/input/emotionpain/Frame_Labels/Frame_Labels/PSPI\"\n    IMAGE_DATASET_PATH = \"/kaggle/input/emotionpain/Images/Images\"\n    image, label = get_label_img(IMAGE_DATASET_PATH, LABEL_DATASET_PATH , index1, index2, index3)\n    plt.imshow(image)\n    plt.title(\"label: \"+ label)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:14:42.643462Z","iopub.execute_input":"2022-12-08T05:14:42.643944Z","iopub.status.idle":"2022-12-08T05:14:42.650584Z","shell.execute_reply.started":"2022-12-08T05:14:42.643903Z","shell.execute_reply":"2022-12-08T05:14:42.649341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img_label(1, 0, 52)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:14:43.409628Z","iopub.execute_input":"2022-12-08T05:14:43.410420Z","iopub.status.idle":"2022-12-08T05:14:43.819867Z","shell.execute_reply.started":"2022-12-08T05:14:43.410361Z","shell.execute_reply":"2022-12-08T05:14:43.818685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multi_image_plot(image_list, dim = (3,3), figsize=(10, 10), title=\"\", sharey=False, sharex=True, tight_layout=False, cmap='gray'):\n    fig, axes = plt.subplots(dim[0], dim[1], figsize=figsize, sharey=sharey, sharex=sharex)\n    fig.suptitle(title, fontsize=16)\n    \n    if tight_layout:\n        fig.tight_layout()\n    cursor = 0\n    for i in range(0,dim[0]):\n        for j in range(0,dim[1]):\n            if cursor >= len(image_list):\n                break\n            axes[i][j].imshow(image_list[cursor][0], cmap=cmap)\n            axes[i][j].axis('off')\n            axes[i][j].set_title(f\"label: {image_list[cursor][1]}\")\n\n            cursor += 1\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:14:43.822212Z","iopub.execute_input":"2022-12-08T05:14:43.823108Z","iopub.status.idle":"2022-12-08T05:14:43.835630Z","shell.execute_reply.started":"2022-12-08T05:14:43.823059Z","shell.execute_reply":"2022-12-08T05:14:43.834347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_img_grid(index_3, index_1=1, index_2=0):\n    LABEL_DATASET_PATH = \"/kaggle/input/emotionpain/Frame_Labels/Frame_Labels/PSPI\"\n    IMAGE_DATASET_PATH = \"/kaggle/input/emotionpain/Images/Images\"\n    image_bucket = []\n    for i in range(index_3, index_3+9):\n        img, label = get_label_img(IMAGE_DATASET_PATH,\n                                   LABEL_DATASET_PATH ,\n                                   index_1, index_2, i)\n        image_bucket.append((img, label))\n    multi_image_plot(image_bucket)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:14:43.837064Z","iopub.execute_input":"2022-12-08T05:14:43.838397Z","iopub.status.idle":"2022-12-08T05:14:43.849403Z","shell.execute_reply.started":"2022-12-08T05:14:43.838335Z","shell.execute_reply":"2022-12-08T05:14:43.847895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img_grid(50, 1, 0)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:14:43.907570Z","iopub.execute_input":"2022-12-08T05:14:43.908931Z","iopub.status.idle":"2022-12-08T05:14:45.009512Z","shell.execute_reply.started":"2022-12-08T05:14:43.908859Z","shell.execute_reply":"2022-12-08T05:14:45.008423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img_grid(90, 3, 3)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:14:45.011812Z","iopub.execute_input":"2022-12-08T05:14:45.012722Z","iopub.status.idle":"2022-12-08T05:14:46.101881Z","shell.execute_reply.started":"2022-12-08T05:14:45.012655Z","shell.execute_reply":"2022-12-08T05:14:46.100483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_large_label_indices(lower_bound = 3):\n    LABEL_DATASET_PATH = \"/kaggle/input/emotionpain/Frame_Labels/Frame_Labels/PSPI\"\n    IMAGE_DATASET_PATH = \"/kaggle/input/emotionpain/Images/Images\"\n    indices_bucket = []\n    for l1, level_1 in enumerate(sorted(os.listdir(LABEL_DATASET_PATH))):\n        level_1_full_path = os.path.join(LABEL_DATASET_PATH, level_1)\n        for l2, level_2 in enumerate(sorted(os.listdir(level_1_full_path))):\n            level_2_full_path = os.path.join(level_1_full_path, level_2)\n            for l3, level_3 in enumerate(sorted(os.listdir(level_2_full_path))):\n                level_3_full_path = os.path.join(level_2_full_path, level_3)\n                with open(level_3_full_path) as f:\n                    label = float(f.readline().strip())\n                    if  label > lower_bound:\n                         indices_bucket.append(((l1, l2, l3), label))\n    \n    return indices_bucket\n                        \n                    ","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:14:46.103983Z","iopub.execute_input":"2022-12-08T05:14:46.104467Z","iopub.status.idle":"2022-12-08T05:14:46.117044Z","shell.execute_reply.started":"2022-12-08T05:14:46.104425Z","shell.execute_reply":"2022-12-08T05:14:46.115599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# indices_bucket = get_large_label_indices()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:17:14.174633Z","iopub.execute_input":"2022-12-08T05:17:14.175069Z","iopub.status.idle":"2022-12-08T05:17:14.181320Z","shell.execute_reply.started":"2022-12-08T05:17:14.175036Z","shell.execute_reply":"2022-12-08T05:17:14.179907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(indices_bucket)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:17:18.336370Z","iopub.execute_input":"2022-12-08T05:17:18.336838Z","iopub.status.idle":"2022-12-08T05:17:18.343886Z","shell.execute_reply.started":"2022-12-08T05:17:18.336801Z","shell.execute_reply":"2022-12-08T05:17:18.342039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# indices_bucket[1500:1510]","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:17:20.799584Z","iopub.execute_input":"2022-12-08T05:17:20.801113Z","iopub.status.idle":"2022-12-08T05:17:20.805994Z","shell.execute_reply.started":"2022-12-08T05:17:20.801065Z","shell.execute_reply":"2022-12-08T05:17:20.805120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_img_grid(85, 0, 5)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:17:24.286755Z","iopub.execute_input":"2022-12-08T05:17:24.287207Z","iopub.status.idle":"2022-12-08T05:17:24.293781Z","shell.execute_reply.started":"2022-12-08T05:17:24.287171Z","shell.execute_reply":"2022-12-08T05:17:24.292178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_img_grid(70, 0, 5)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:17:26.860319Z","iopub.execute_input":"2022-12-08T05:17:26.860775Z","iopub.status.idle":"2022-12-08T05:17:26.867385Z","shell.execute_reply.started":"2022-12-08T05:17:26.860739Z","shell.execute_reply":"2022-12-08T05:17:26.865881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_img_grid(345, 24, 6)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:17:29.884521Z","iopub.execute_input":"2022-12-08T05:17:29.884936Z","iopub.status.idle":"2022-12-08T05:17:29.891252Z","shell.execute_reply.started":"2022-12-08T05:17:29.884901Z","shell.execute_reply":"2022-12-08T05:17:29.889776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_img_grid(163, 23, 1)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:17:33.182791Z","iopub.execute_input":"2022-12-08T05:17:33.183227Z","iopub.status.idle":"2022-12-08T05:17:33.188834Z","shell.execute_reply.started":"2022-12-08T05:17:33.183191Z","shell.execute_reply":"2022-12-08T05:17:33.187831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport glob\ndef gen_video(index_1, index_2, index_3_range, name):\n    LABEL_DATASET_PATH = \"/kaggle/input/emotionpain/Frame_Labels/Frame_Labels/PSPI\"\n    IMAGE_DATASET_PATH = \"/kaggle/input/emotionpain/Images/Images\"\n    frameSize = (500, 500)\n    out = cv2.VideoWriter(name, cv2.VideoWriter_fourcc('M','J','P','G'),\n                          10, frameSize)\n\n    n_i = sorted(os.listdir(IMAGE_DATASET_PATH))[index_1]\n    level_1_i = os.path.join(IMAGE_DATASET_PATH, n_i)\n    m_i = sorted(os.listdir(level_1_i))[index_2]\n    level_2_i = os.path.join(level_1_i, m_i)\n#     o_i = sorted(os.listdir(level_2_i))\n    for img_path in sorted(glob.glob(f\"{level_2_i}/*\"))[index_3_range[0]:index_3_range[1]]:\n        img = cv2.imread(img_path)\n        resized = cv2.resize(img, (500,500), interpolation = cv2.INTER_AREA)\n        out.write(resized)\n    out.release()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:38:00.281574Z","iopub.execute_input":"2022-12-08T10:38:00.282020Z","iopub.status.idle":"2022-12-08T10:38:00.321026Z","shell.execute_reply.started":"2022-12-08T10:38:00.281981Z","shell.execute_reply":"2022-12-08T10:38:00.320007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gen_video(0, 5, (0, 300), 'output_video3.avi')","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:17:37.610849Z","iopub.execute_input":"2022-12-08T05:17:37.611402Z","iopub.status.idle":"2022-12-08T05:17:37.617258Z","shell.execute_reply.started":"2022-12-08T05:17:37.611361Z","shell.execute_reply":"2022-12-08T05:17:37.615711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing Training Dataset","metadata":{}},{"cell_type":"markdown","source":"- crop faces, labels","metadata":{}},{"cell_type":"code","source":"from random import shuffle\nfrom tqdm import tqdm\nimport cv2\nfrom pickle import dump, load\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense,BatchNormalization\nimport pickle as pk\nfrom tensorflow.keras import applications","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:38:04.251314Z","iopub.execute_input":"2022-12-08T10:38:04.251990Z","iopub.status.idle":"2022-12-08T10:38:10.324214Z","shell.execute_reply.started":"2022-12-08T10:38:04.251949Z","shell.execute_reply":"2022-12-08T10:38:10.323065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_dataset(Label_Dir, TRAIN_DIR, IMG_SIZE):\n    harrcascade_face_xml = \"/kaggle/input/haarcascades/haarcascade_frontalface_default.xml\"\n    face_cascade = cv2.CascadeClassifier(harrcascade_face_xml)\n    training_data = []\n    label_data=[]\n\n    c0 = c1 = res =0\n    #reading label only \n    for folder in os.listdir(Label_Dir):\n        c0=0\n        for inner_folder in os.listdir((Label_Dir+'/'+folder)):\n            path = os.path.join(Label_Dir,folder+'/'+ inner_folder)\n            for file in os.listdir(path):\n                file=os.path.join(path+'/'+file)\n                with open(file) as f:\n                    label = float(f.readline().strip())\n                    if (label==0 and c0<340):\n                        label_data.append(0)\n                        res+=1\n                        c0+=1\n                    if(label!=0):\n                        label_data.append(1)\n                        c1+=1\n                    f.close()\n    \n    label_data.append(-1)\n    print(str(res) + ' ' + str(c1))\n    #reading images and it's labels\n    c = c0 = c1 = res = 0\n    print(len(label_data))\n    for folder in os.listdir(TRAIN_DIR):\n        c0=0\n        for inner_folder in os.listdir((TRAIN_DIR+'/'+folder)):\n            path = os.path.join(TRAIN_DIR,folder+'/'+ inner_folder)\n            for img in tqdm(os.listdir(path)):\n                img=os.path.join(path+'/'+img)\n                img_data = cv2.imread(img,cv2.IMREAD_COLOR)#cv2.IMREAD_COLOR\n                img_data_gray = cv2.cvtColor(img_data,cv2.COLOR_RGB2GRAY)\n                faces = face_cascade.detectMultiScale(img_data_gray, 1.1, 4)\n                \n                if not len(faces):\n                    continue\n                    \n                x, y, w, h = faces[0]\n                face_cropped = img_data[y: y+h, x: x+w]\n                img_data = cv2.resize(face_cropped, (IMG_SIZE, IMG_SIZE))\n                \n                if (label_data[c]==-1):break\n                if (label_data[c]==0 and c0<340):\n                    training_data.append([np.array(img_data), label_data[c]])\n                    c0+=1\n                    res+=1\n                    c+=1\n                if (label_data[c]!=0):\n                    training_data.append([np.array(img_data), label_data[c]])\n                    c+=1\n                    c1+=1\n                if c % 100 == 0:\n                    print(\"saving dataset...\")\n                    dump(training_data, open('/kaggle/working/training_data_rgb_checkpoint.pkl', 'wb'))\n\n            #print(str(res) + ' ' + str(c1))      \n\n    print(str(res) + ' ' + str(c1))           \n\n    shuffle(training_data) \n    dump(training_data, open('/kaggle/working/training_data_rgb.pkl', 'wb'))\n    return training_data","metadata":{"execution":{"iopub.status.busy":"2022-12-08T06:38:59.838154Z","iopub.execute_input":"2022-12-08T06:38:59.839430Z","iopub.status.idle":"2022-12-08T06:38:59.900991Z","shell.execute_reply.started":"2022-12-08T06:38:59.839383Z","shell.execute_reply":"2022-12-08T06:38:59.900029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LABEL_DATASET_PATH = \"/kaggle/input/emotionpain/Frame_Labels/Frame_Labels/PSPI\"\nIMAGE_DATASET_PATH = \"/kaggle/input/emotionpain/Images/Images\"\ntraining_data = generate_dataset(LABEL_DATASET_PATH, IMAGE_DATASET_PATH  , 128)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:38:10.326308Z","iopub.execute_input":"2022-12-08T10:38:10.326955Z","iopub.status.idle":"2022-12-08T10:38:10.554214Z","shell.execute_reply.started":"2022-12-08T10:38:10.326899Z","shell.execute_reply":"2022-12-08T10:38:10.552478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(training_data)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T07:33:04.462702Z","iopub.execute_input":"2022-12-08T07:33:04.463987Z","iopub.status.idle":"2022-12-08T07:33:04.476992Z","shell.execute_reply.started":"2022-12-08T07:33:04.463922Z","shell.execute_reply":"2022-12-08T07:33:04.475636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualizing training dataset","metadata":{}},{"cell_type":"code","source":"# loading saved training data\ndataset_path = \"/kaggle/input/pain-dataset/training_data_rgb.pkl\"\nif (os.path.exists(dataset_path)):\n        training_data = load(open(dataset_path, 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:12:08.886437Z","iopub.execute_input":"2022-12-08T10:12:08.887130Z","iopub.status.idle":"2022-12-08T10:12:15.123613Z","shell.execute_reply.started":"2022-12-08T10:12:08.887088Z","shell.execute_reply":"2022-12-08T10:12:15.122448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = training_data[70]\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.title(label)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T08:40:53.096269Z","iopub.execute_input":"2022-12-08T08:40:53.096848Z","iopub.status.idle":"2022-12-08T08:40:53.334849Z","shell.execute_reply.started":"2022-12-08T08:40:53.096804Z","shell.execute_reply":"2022-12-08T08:40:53.333860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = training_data[3000]\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.title(label)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T08:42:33.534128Z","iopub.execute_input":"2022-12-08T08:42:33.535118Z","iopub.status.idle":"2022-12-08T08:42:33.763762Z","shell.execute_reply.started":"2022-12-08T08:42:33.535078Z","shell.execute_reply":"2022-12-08T08:42:33.762806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-08T07:35:11.199462Z","iopub.execute_input":"2022-12-08T07:35:11.199967Z","iopub.status.idle":"2022-12-08T07:35:11.207595Z","shell.execute_reply.started":"2022-12-08T07:35:11.199930Z","shell.execute_reply":"2022-12-08T07:35:11.206629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model building","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten,Conv2D,MaxPooling2D\nfrom tensorflow.keras import applications\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:38:20.019800Z","iopub.execute_input":"2022-12-08T10:38:20.020994Z","iopub.status.idle":"2022-12-08T10:38:20.027733Z","shell.execute_reply.started":"2022-12-08T10:38:20.020903Z","shell.execute_reply":"2022-12-08T10:38:20.026193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Model_vgg(ImgSize, fine_tune=0):\n    pretrained_model = applications.vgg16.VGG16(weights='imagenet', include_top=False,input_shape=ImgSize)\n    model = Sequential()\n    \n    for layer in pretrained_model.layers:\n        model.add(layer)\n    \n    # freezing vgg16 layers\n    if fine_tune > 0:\n        for layer in model.layers[:-fine_tune]:\n            layer.trainable = False\n    else:\n        for layer in model.layers:\n            layer.trainable = False\n    \n    # building dense layer\n    model.add(Flatten())\n    model.add(Dense(1000,activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(500, activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(228, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(100, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(10, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(2,activation='softmax'))\n    \n    model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:38:47.339575Z","iopub.execute_input":"2022-12-08T10:38:47.340026Z","iopub.status.idle":"2022-12-08T10:38:47.351996Z","shell.execute_reply.started":"2022-12-08T10:38:47.339989Z","shell.execute_reply":"2022-12-08T10:38:47.350880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model_vgg((128, 128, 3), fine_tune=1)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:39:14.087503Z","iopub.execute_input":"2022-12-08T10:39:14.087979Z","iopub.status.idle":"2022-12-08T10:39:18.934467Z","shell.execute_reply.started":"2022-12-08T10:39:14.087939Z","shell.execute_reply":"2022-12-08T10:39:18.932081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing train test dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:43:47.693064Z","iopub.execute_input":"2022-12-08T10:43:47.694246Z","iopub.status.idle":"2022-12-08T10:43:48.365655Z","shell.execute_reply.started":"2022-12-08T10:43:47.694204Z","shell.execute_reply":"2022-12-08T10:43:48.364556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_STATE = 23\n\ndef train_test_split_(dataset_path, test_size=None):\n    #loading saved dataset\n    if (os.path.exists(dataset_path)):\n        training_data = load(open(dataset_path, 'rb'))\n    \n    x = np.array([img for img, label in training_data])\n    y = np.array([label for img, label in training_data])\n    \n    if test_size:\n        x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=test_size, random_state=RANDOM_STATE)\n    else:\n        x_train, y_train = x, y\n        x_test, y_test = None, None\n\n    return (x_train, y_train), (x_test, y_test)\n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:43:49.050634Z","iopub.execute_input":"2022-12-08T10:43:49.051438Z","iopub.status.idle":"2022-12-08T10:43:49.059204Z","shell.execute_reply.started":"2022-12-08T10:43:49.051390Z","shell.execute_reply":"2022-12-08T10:43:49.058081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = train_test_split_(\"/kaggle/input/pain-dataset/training_data_rgb.pkl\", test_size=0.2)\nx_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:43:49.751408Z","iopub.execute_input":"2022-12-08T10:43:49.751835Z","iopub.status.idle":"2022-12-08T10:43:51.129062Z","shell.execute_reply.started":"2022-12-08T10:43:49.751789Z","shell.execute_reply":"2022-12-08T10:43:51.127975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model training","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:43:56.796915Z","iopub.execute_input":"2022-12-08T10:43:56.798049Z","iopub.status.idle":"2022-12-08T10:43:56.803849Z","shell.execute_reply.started":"2022-12-08T10:43:56.797983Z","shell.execute_reply":"2022-12-08T10:43:56.802572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(hist):\n    fig = plt.figure()\n    plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n    plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n    fig.suptitle('Accuracy', fontsize=20)\n    plt.legend(loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:43:37.029631Z","iopub.execute_input":"2022-12-08T10:43:37.030079Z","iopub.status.idle":"2022-12-08T10:43:37.036819Z","shell.execute_reply.started":"2022-12-08T10:43:37.030040Z","shell.execute_reply":"2022-12-08T10:43:37.035596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_generator = ImageDataGenerator(\n#     horizontal_flip=True,\n#     vertical_flip=True,\n#     rotation_range=(0, 0.5),\n#     rescale=0.2,\n#     brightness_range= (0, 0.3)\n# )\n\n# data_generator.fit(x_train)\n\n# train_gen = data_generator.flow(x_train, y_train, batch_size=32, seed=RANDOM_STATE)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T09:52:27.175082Z","iopub.execute_input":"2022-12-08T09:52:27.175428Z","iopub.status.idle":"2022-12-08T09:52:37.434914Z","shell.execute_reply.started":"2022-12-08T09:52:27.175394Z","shell.execute_reply":"2022-12-08T09:52:37.433757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(x_train, y_train, epochs=15, verbose=1, validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T08:55:35.523657Z","iopub.execute_input":"2022-12-08T08:55:35.524072Z","iopub.status.idle":"2022-12-08T09:01:09.524872Z","shell.execute_reply.started":"2022-12-08T08:55:35.524037Z","shell.execute_reply":"2022-12-08T09:01:09.523854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(hist)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T09:02:08.604527Z","iopub.execute_input":"2022-12-08T09:02:08.604978Z","iopub.status.idle":"2022-12-08T09:02:08.835747Z","shell.execute_reply.started":"2022-12-08T09:02:08.604937Z","shell.execute_reply":"2022-12-08T09:02:08.834798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(x_train, y_train, epochs=15, verbose=1, validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T09:02:30.131400Z","iopub.execute_input":"2022-12-08T09:02:30.131780Z","iopub.status.idle":"2022-12-08T09:08:07.210288Z","shell.execute_reply.started":"2022-12-08T09:02:30.131749Z","shell.execute_reply":"2022-12-08T09:08:07.209138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(hist)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T09:08:07.212232Z","iopub.execute_input":"2022-12-08T09:08:07.212834Z","iopub.status.idle":"2022-12-08T09:08:07.487328Z","shell.execute_reply.started":"2022-12-08T09:08:07.212790Z","shell.execute_reply":"2022-12-08T09:08:07.486415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(x_train, y_train, epochs=15, verbose=1, validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T09:02:26.176495Z","iopub.status.idle":"2022-12-08T09:02:26.176986Z","shell.execute_reply.started":"2022-12-08T09:02:26.176722Z","shell.execute_reply":"2022-12-08T09:02:26.176745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(hist)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T08:17:27.494240Z","iopub.execute_input":"2022-12-08T08:17:27.495250Z","iopub.status.idle":"2022-12-08T08:17:27.766746Z","shell.execute_reply.started":"2022-12-08T08:17:27.495210Z","shell.execute_reply":"2022-12-08T08:17:27.765836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_test value count\nnp.unique(y_train, return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T08:18:05.461614Z","iopub.execute_input":"2022-12-08T08:18:05.462058Z","iopub.status.idle":"2022-12-08T08:18:05.470557Z","shell.execute_reply.started":"2022-12-08T08:18:05.462021Z","shell.execute_reply":"2022-12-08T08:18:05.469607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(x_train, y_train, epochs=5, verbose=1, validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T08:18:31.792560Z","iopub.execute_input":"2022-12-08T08:18:31.792972Z","iopub.status.idle":"2022-12-08T08:20:26.101476Z","shell.execute_reply.started":"2022-12-08T08:18:31.792925Z","shell.execute_reply":"2022-12-08T08:20:26.100369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(hist)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T08:20:26.103649Z","iopub.execute_input":"2022-12-08T08:20:26.104063Z","iopub.status.idle":"2022-12-08T08:20:26.356705Z","shell.execute_reply.started":"2022-12-08T08:20:26.104008Z","shell.execute_reply":"2022-12-08T08:20:26.355781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"/kaggle/working/model_acc_80.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-12-08T08:20:48.620432Z","iopub.execute_input":"2022-12-08T08:20:48.620788Z","iopub.status.idle":"2022-12-08T08:20:48.884338Z","shell.execute_reply.started":"2022-12-08T08:20:48.620752Z","shell.execute_reply":"2022-12-08T08:20:48.883353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Prediction","metadata":{}},{"cell_type":"code","source":"def predict(image, model_path= \"/kaggle/working/model_acc_80.h5\"):\n    IMG_SHAPE = 128\n    model = keras.models.load_model(model_path)\n    \n    # detect face in the image\n    harrcascade_face_xml = \"/kaggle/input/haarcascades/haarcascade_frontalface_default.xml\"\n    face_cascade = cv2.CascadeClassifier(harrcascade_face_xml)\n    \n    img_data_gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n    faces = face_cascade.detectMultiScale(img_data_gray, 1.1, 4)\n    \n    if not len(faces):\n        print(\"no face detected\")\n        return\n                    \n    x, y, w, h = faces[0]\n    face_cropped = image[y: y+h, x: x+w]\n    img_data = cv2.resize(face_cropped, (IMG_SHAPE, IMG_SHAPE))\n    return np.argmax(model.predict(img_data.reshape(-1, IMG_SHAPE, IMG_SHAPE, 3)))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:59:48.765601Z","iopub.execute_input":"2022-12-08T10:59:48.766074Z","iopub.status.idle":"2022-12-08T10:59:48.774808Z","shell.execute_reply.started":"2022-12-08T10:59:48.766037Z","shell.execute_reply":"2022-12-08T10:59:48.773522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !wget \"https://www.noldus.com/static/images/core-blog/mobile/measuring-painful-faces-1583143928.jpg\"","metadata":{"execution":{"iopub.status.busy":"2022-12-08T08:36:39.495847Z","iopub.execute_input":"2022-12-08T08:36:39.496625Z","iopub.status.idle":"2022-12-08T08:36:39.501057Z","shell.execute_reply.started":"2022-12-08T08:36:39.496577Z","shell.execute_reply":"2022-12-08T08:36:39.499969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = cv2.imread(\"/kaggle/working/measuring-painful-faces-1583143928.jpg\")\npredict(image)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:59:55.646272Z","iopub.execute_input":"2022-12-08T10:59:55.646666Z","iopub.status.idle":"2022-12-08T10:59:57.901009Z","shell.execute_reply.started":"2022-12-08T10:59:55.646633Z","shell.execute_reply":"2022-12-08T10:59:57.899872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = training_data[3000]\npredict(img), label","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:59:58.294790Z","iopub.execute_input":"2022-12-08T10:59:58.296233Z","iopub.status.idle":"2022-12-08T10:59:58.324162Z","shell.execute_reply.started":"2022-12-08T10:59:58.296183Z","shell.execute_reply":"2022-12-08T10:59:58.322404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Xception pretrained model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import xception","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:41:40.086515Z","iopub.execute_input":"2022-12-08T10:41:40.087719Z","iopub.status.idle":"2022-12-08T10:41:40.095301Z","shell.execute_reply.started":"2022-12-08T10:41:40.087673Z","shell.execute_reply":"2022-12-08T10:41:40.094222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Model_customized():\n    conv_layer = xception.Xception(include_top=False, input_shape=(128, 128, 3))\n    model = Sequential()\n\n    model.add(conv_layer)\n    \n    # freezing vgg16 layers\n    for layer in model.layers[:-2]:\n        layer.trainable = False\n    \n    # building dense layer\n    model.add(Flatten())\n    model.add(Dense(1000,activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(500, activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(228, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(100, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(10, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(2,activation='softmax'))\n    \n    model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:41:44.694286Z","iopub.execute_input":"2022-12-08T10:41:44.694691Z","iopub.status.idle":"2022-12-08T10:41:44.705188Z","shell.execute_reply.started":"2022-12-08T10:41:44.694656Z","shell.execute_reply":"2022-12-08T10:41:44.704114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model_customized()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:41:47.563903Z","iopub.execute_input":"2022-12-08T10:41:47.564728Z","iopub.status.idle":"2022-12-08T10:41:49.393297Z","shell.execute_reply.started":"2022-12-08T10:41:47.564686Z","shell.execute_reply":"2022-12-08T10:41:49.392113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T09:31:57.228021Z","iopub.execute_input":"2022-12-08T09:31:57.228418Z","iopub.status.idle":"2022-12-08T09:31:57.245597Z","shell.execute_reply.started":"2022-12-08T09:31:57.228385Z","shell.execute_reply":"2022-12-08T09:31:57.244509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(x_train, y_train, epochs=15, verbose=1, validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T09:31:58.424379Z","iopub.execute_input":"2022-12-08T09:31:58.425068Z","iopub.status.idle":"2022-12-08T09:52:25.473011Z","shell.execute_reply.started":"2022-12-08T09:31:58.425030Z","shell.execute_reply":"2022-12-08T09:52:25.471877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(hist)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T09:55:16.522648Z","iopub.execute_input":"2022-12-08T09:55:16.523151Z","iopub.status.idle":"2022-12-08T09:55:16.759988Z","shell.execute_reply.started":"2022-12-08T09:55:16.523112Z","shell.execute_reply":"2022-12-08T09:55:16.758848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(x_train, y_train, epochs=15, verbose=1, validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T09:55:22.119030Z","iopub.execute_input":"2022-12-08T09:55:22.119410Z","iopub.status.idle":"2022-12-08T10:10:13.619041Z","shell.execute_reply.started":"2022-12-08T09:55:22.119375Z","shell.execute_reply":"2022-12-08T10:10:13.616256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(hist)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation to improve the accuracy","metadata":{}},{"cell_type":"code","source":"data_generator = ImageDataGenerator(\n    horizontal_flip=True\n)\n\nbatch_size = 64\ndata_generator.fit(x_train)\n\ntrain_gen = data_generator.flow(x_train, y_train, batch_size=batch_size, seed=RANDOM_STATE)\ndel x_train\ndel y_train\ndel training_data","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:44:07.492762Z","iopub.execute_input":"2022-12-08T10:44:07.493853Z","iopub.status.idle":"2022-12-08T10:44:10.561087Z","shell.execute_reply.started":"2022-12-08T10:44:07.493813Z","shell.execute_reply":"2022-12-08T10:44:10.559961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit_generator(train_gen, \n                    epochs=15,  # one forward/backward pass of training data\n                    steps_per_epoch=x_train.shape[0]//batch_size,  # number of images comprising of one epoch\n                    validation_data=(x_test, y_test), # Or validation_data=valid_generator\n                    validation_steps=x_test.shape[0]//batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:44:14.073366Z","iopub.execute_input":"2022-12-08T10:44:14.074044Z","iopub.status.idle":"2022-12-08T10:58:02.440307Z","shell.execute_reply.started":"2022-12-08T10:44:14.074000Z","shell.execute_reply":"2022-12-08T10:58:02.435616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(hist)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:36:12.504738Z","iopub.execute_input":"2022-12-08T10:36:12.506049Z","iopub.status.idle":"2022-12-08T10:36:12.989312Z","shell.execute_reply.started":"2022-12-08T10:36:12.505991Z","shell.execute_reply":"2022-12-08T10:36:12.987746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit_generator(train_gen, \n                    epochs=15,  # one forward/backward pass of training data\n                    steps_per_epoch=x_train.shape[0]//batch_size,  # number of images comprising of one epoch\n                    validation_data=(x_test, y_test), # Or validation_data=valid_generator\n                    validation_steps=x_test.shape[0]//batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T10:34:59.480225Z","iopub.status.idle":"2022-12-08T10:34:59.481117Z","shell.execute_reply.started":"2022-12-08T10:34:59.480811Z","shell.execute_reply":"2022-12-08T10:34:59.480848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}